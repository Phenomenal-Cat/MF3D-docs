========================================
:fa:`book` MF3D Research
========================================

Visual stimuli generated by the MF3D project are being actively used by neuroscience research labs across the world. Below are a subset of the published articles and conference abstracts reporting data from experiments using this freely available scientific resource.


:fa:`book` Publications
==========================

.. panels::
  :container: container-lg pb-3
  :column: col-lg-4 col-md-4 col-sm-6 col-xs-12 p-2
  :img-top-cls: pl-0 pr-0

  ---
  :img-top: _images/Figures/Khandhadia_GraphicalAbstract.png
  :badge:`E.phys,badge-warning badge-pill` 
  ^^^^^^^^

  .. _Khandhadia2021:

  `Khandhadia AP, Murphy AP, Romanksi LM, Bizley JK, Leopold DA (2021). <https://doi.org/10.1016/j.cub.2021.01.102>`_
  **Audiovisual Integration in Macaque Face Patch Neurons**

  +++++
  .. link-button:: https://doi.org/10.1016/j.cub.2021.01.102
    :type: url
    :text: Current Biology
    :classes: btn-outline-primary btn-block

  .. image:: _images/Logos/OpenAccess.png
    :height: 30
    :target: https://publicaccess.nih.gov/
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/PDF_button.png
    :height: 30
    :target: _static/PDFs/MF3D_Papers/Khandhadia_2021-Audiovisual.pdf
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/PubMed_button.png
    :height: 30
    :target: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8521527/
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/GoogleScholar.png
    :height: 30
    :target: https://scholar.google.com/scholar?cites=3380824935233534645&as_sdt=20000005&sciodt=0,21&hl=en
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/ResearchGate.png
    :height: 30
    :target: https://www.researchgate.net/publication/349626537_Audiovisual_integration_in_macaque_face_patch_neurons


  ---
  :img-top: _images/Figures/Taubert2020_Fig6.png
  :badge:`fMRI,badge-success badge-pill` 
  ^^^^^^^^
  .. _Taubert2020:

  `Taubert J, Japee S, Murphy AP, Tardiff CT, Koele EA, Kumar S, Leopold DA, & Ungerleider LG (2020). <https://doi.org/10.1523/JNEUROSCI.0524-20.2020>`_
  **Parallel processing of facial expression and head orientation in the macaque brain** 
  


  +++++
  .. link-button:: https://doi.org/10.1523/JNEUROSCI.0524-20.2020
    :type: url
    :text: J.Neurosci.
    :classes: btn-outline-primary btn-block

  .. image:: _images/Logos/OpenAccess.png
    :height: 30
    :target: https://publicaccess.nih.gov/
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/PDF_button.png
    :height: 30
    :target: _static/PDFs/MF3D_Papers/Taubert_2020-Expression_orientation.pdf
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/PubMed_button.png
    :height: 30
    :target: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7574659/
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/GoogleScholar.png
    :height: 30
    :target: https://scholar.google.com/scholar?cites=9006831545148241977&as_sdt=5,47&sciodt=0,47&hl=en
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/ResearchGate.png
    :height: 30
    :target: https://www.researchgate.net/publication/344279905_Parallel_processing_of_facial_expression_and_head_orientation_in_the_macaque_brain

  ---
  :img-top: _images/ML_Figs/MurphyLeopold_GraphicalAbstract.png
  :badge:`Methods,badge-danger badge-pill` :badge:`E.phys,badge-warning badge-pill` 
  ^^^^^^^^

  .. _Murphy2019:

  `Murphy AP & Leopold DA, (2019). <https://doi.org/10.1016/j.jneumeth.2019.06.001>`_
  **A parameterized digital 3D model of the Rhesus macaque face for investigating the visual processing of social cues**



  +++++
  .. link-button:: https://doi.org/10.1016/j.jneumeth.2019.06.001
    :type: url
    :text: J.Neurosci.Methods
    :classes: btn-outline-primary btn-block

  .. image:: _images/Logos/OpenAccess.png
    :height: 30
    :target: https://publicaccess.nih.gov/
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/PDF_button.png
    :height: 30
    :target: _static/PDFs/MF3D_Papers/MurphyLeopold_2019-MacaqueAvatar.pdf
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/PubMed_button.png
    :height: 30
    :target: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7446874/
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/GoogleScholar.png
    :height: 30
    :target: https://scholar.google.com/scholar?cites=9006831545148241977&as_sdt=5,47&sciodt=0,47&hl=en
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/ResearchGate.png
    :height: 30
    :target: https://www.researchgate.net/publication/333700889_A_parameterized_digital_3D_model_of_the_Rhesus_macaque_face_for_investigating_the_visual_processing_of_social_cues


:fa:`pencil` Pre-prints / in prep.
===================================


.. panels::
  :container: container-lg pb-3
  :column: col-lg-4 col-md-4 col-sm-6 col-xs-12 p-2
  :img-top-cls: pl-0 pr-0

  ---
  :img-top: _images/Figures/Khandhadia_2022_Fig2.png
  :badge:`E.phys,badge-warning badge-pill` 
  ^^^^^^^^

  .. _Khandhadia2022:

  Khandhadia AP, Murphy AP, Koyano KW, Leopold DA (in prep).
  **Neural tuning for physical size in macaque face patch neurons**

  +++++
  .. dropdown:: Abstract

    Neurons in the primate inferior temporal cortex respond selectively to complex visual form, with some populations specialized for important object categories such as faces. A neuron’s selectivity for a particular image is often independent of its scale on the display. At the same time, recent work found that the responses of neurons in the anterior fundus (AF) face patch were strongly shaped by scale, and particularly the size of faces appearing on the screen. This and other observations raise the question of how size may be represented in object selective cortex, and particularly whether neural responses to an object are more linked to its angular retinal subtense or its actual physical size.  We approached this question by testing a population of AF neurons while systematically varying the geometric parameters of an avatar stimulus of a macaque face.  Recordings of neural responses to joint stereoscopic manipulations of the face’s size and distance revealed two previously unreported features of face selective neurons. First, most neurons exhibited their strongest responses to extreme sizes.  Second, for many neurons, the physical 3D size of the face in centimeters, rather than the angular retinal subtense, best predicted the spiking responses.  These findings indicate that the real-world geometry of objects in space is represented explicitly in high-level visual cortex, including in face-selective neurons. 

  ---
  :img-top: _images/Figures/Murphy2022_Fig1.png
  :badge:`E.phys,badge-warning badge-pill` 
  ^^^^^^^^

  .. _Murphy2022:

  Murphy AP, Esch EM, Khandhadia AP, Koyano KW, Leopold DA (in prep).
  **Natural stereoscopic depth amplifies face cell responses in macaque**

  +++++
  .. dropdown:: Abstract

    This study used stereoscopic 3D presentations of the macaque avatar faces to generate realistic depth percepts. Chronic exctracellular neural recordings from three of the face-selective regions of inferotemporal (IT) cortex revealed that many face selective neurons were tuned to faces with natural stereoscopic depth profiles, as opposed to 2D or inverted depth faces. This finding was robust across variations of the stimulus position-in-depth, suggesting that face cells are tuned to 3D shape rather than to specific binocular disparities.
  


:fa:`camera` Cameo Appearances
==================================

The macaque avatar appears in figures for illustration purposes (but was not used as an experimental stimulus) in the following articles and commentaries:

* **Fan S, Dal Monte O, Chang SWC (2021)**. `Levels of naturalism in social neuroscience research <https://doi.org/10.1016/j.isci.2021.102702>`_. *iScience*

* **Beauchamp MS (2021)**. `Face and Voice Perception: Monkey see, monkey hear <https://doi.org/10.1016/j.cub.2021.02.060>`_. *Curr.Bio.*

* **Koyano KW, Jones AP, McMahon DBT, Waidmann EN, Russ BE, Leopold DA (2021)**. `Dynamic Suppression of Average Facial Structure Shapes Neural Tuning in Three Macaque Face Patches <https://doi.org/10.1016/j.cub.2020.09.070>`_. *Curr.Bio.*

* **Taubert J & Japee S (2021)**. `Using FACS to trace the neural specializations underlying the recognition of facial expressions: A commentary on Waller et al. (2020) <https://doi.org/10.1016/j.neubiorev.2020.10.016>`_. *Neu.Bio.Rev.*

* **Taubert J, Wardle SG, Ungerleider LG (2020)**. `What does a “face cell” want? <https://doi.org/10.1016/j.pneurobio.2020.101880>`_. *P.Neuro.Bio.*

* **Leopold DA & Krauzlis RJ (2020)**. `How the brain pays attention to others’ attention <https://www.pnas.org/content/117/8/3901>`_. *Curr.Bio.*


:fa:`thumbs-up` Acknowledgements
=========================================

This work was funded by the `National Institute of Mental Health (NIMH) <https://www.nimh.nih.gov/index.shtml>`_ intramural program and utilized the `Neurophysiology Imaging Facility (NIF) <https://www.nimh.nih.gov/research/research-conducted-at-nimh/research-areas/research-support-services/nif/index.shtml>`_ and NIH's `HPC Biowulf cluster <https://hpc.nih.gov/>`_ resources. Stimuli are hosted on `Figshare <https://figshare.com/projects/MF3D_Release_1_A_visual_stimulus_set_of_parametrically_controlled_CGI_macaque_faces_for_research/64544>`_ under the `Creative Commons CC-BY-NC 4.0 <https://creativecommons.org/licenses/by-nc/4.0/>`_ license, while software tools are hosted on `GitHub <https://github.com/MonkeyGone2Heaven/MF3D-Tools>`_ under the `GNU General Public License GNU GPLv3 <https://choosealicense.com/licenses/gpl-3.0/#>`_. All visual stimulus renders were generated using the open-source software `Blender <www.blender.org>`_.



:fa:`handshake` Collaborations
==========================================

Since the initial launch of MF3D, many researchers have contacted us with inquiries regarding adaptation or development of the model's features to address specific scientific questions. At present, our approach is to assess the feasibility of each feature request, and if we determine the required development of the model to be within our capabilities then we will offer to collaborate. This has the advantage for the requester that they don’t have to invest time and effort to learn the technical aspects of 3D animation and rendering in order to get their stimuli, while allowing us to avoid conflicts that could arise from multiple research groups working on the same experimental question simultaneously.
