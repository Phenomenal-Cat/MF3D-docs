========================================
:fa:`book` MF3D Research
========================================

Visual stimuli generated by the MF3D project are being actively used by neuroscience research labs across the world. Below are a subset of the published articles and conference abstracts reporting data from experiments using this freely available scientific resource.

.. contents::
  :local:


:fa:`book` Publications
==========================

.. panels::
  :container: container-lg p-0 border-0
  :column: col-lg-12 p-2 border-0

  ---

  .. image:: _images/Figures/Khandhadia_2023_Fig1_APMversion.png
    :width: 200
    :align: right

  .. _Khandhadia2023:

  `Khandhadia AP, Murphy AP, Esch EM, Koyano KW, Leopold DA (2023). <https://doi.org/10.1073/pnas.2214996120>`_
  **Encoding of 3D physical dimensions by face-selective cortical neurons**. :link-badge:`https://doi.org/10.1073/pnas.2214996120,"PNAS",cls=badge-primary text-white`

  +++++
  .. image:: _images/Logos/OpenAccess.png
    :height: 30
    :target: https://publicaccess.nih.gov/
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/PDF_button.png
    :height: 30
    :target: _static/PDFs/MF3D_Papers/Khandhadia_2023-3D.pdf
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/PubMed_button.png
    :height: 30
    :target: https://www.ncbi.nlm.nih.gov/pmc/articles/
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/GoogleScholar.png
    :height: 30
    :target: https://scholar.google.com/
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/ResearchGate.png
    :height: 30
    :target: https://www.researchgate.net/publication/



  ---
  .. image:: _images/Figures/Khandhadia_GraphicalAbstract.png
    :width: 200
    :align: right

  .. _Khandhadia2021:

  `Khandhadia AP, Murphy AP, Romanksi LM, Bizley JK, Leopold DA (2021). <https://doi.org/10.1016/j.cub.2021.01.102>`_
  **Audiovisual Integration in Macaque Face Patch Neurons**. :link-badge:`https://doi.org/10.1016/j.cub.2021.01.102,"Current Biology",cls=badge-primary text-white`

  +++++
  .. image:: _images/Logos/OpenAccess.png
    :height: 30
    :target: https://publicaccess.nih.gov/
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/PDF_button.png
    :height: 30
    :target: _static/PDFs/MF3D_Papers/Khandhadia_2021-Audiovisual.pdf
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/PubMed_button.png
    :height: 30
    :target: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8521527/
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/GoogleScholar.png
    :height: 30
    :target: https://scholar.google.com/scholar?cites=3380824935233534645&as_sdt=20000005&sciodt=0,21&hl=en
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/ResearchGate.png
    :height: 30
    :target: https://www.researchgate.net/publication/349626537_Audiovisual_integration_in_macaque_face_patch_neurons


  ---

  .. image:: _images/Figures/Taubert2020_Fig6.png
    :width: 200
    :align: right

  .. _Taubert2020:

  `Taubert J, Japee S, Murphy AP, Tardiff CT, Koele EA, Kumar S, Leopold DA, & Ungerleider LG (2020). <https://doi.org/10.1523/JNEUROSCI.0524-20.2020>`_
  **Parallel processing of facial expression and head orientation in the macaque brain**. :link-badge:`https://doi.org/10.1523/JNEUROSCI.0524-20.2020,"J.Neurosci.",cls=badge-primary text-white`
 

  +++++
  .. image:: _images/Logos/OpenAccess.png
    :height: 30
    :target: https://publicaccess.nih.gov/
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/PDF_button.png
    :height: 30
    :target: _static/PDFs/MF3D_Papers/Taubert_2020-Expression_orientation.pdf
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/PubMed_button.png
    :height: 30
    :target: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7574659/
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/GoogleScholar.png
    :height: 30
    :target: https://scholar.google.com/scholar?cites=9006831545148241977&as_sdt=5,47&sciodt=0,47&hl=en
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/ResearchGate.png
    :height: 30
    :target: https://www.researchgate.net/publication/344279905_Parallel_processing_of_facial_expression_and_head_orientation_in_the_macaque_brain

  ---

  .. image:: _images/ML_Figs/MurphyLeopold_GraphicalAbstract.png
    :width: 200
    :align: right

  .. _Murphy2019:

  `Murphy AP & Leopold DA, (2019). <https://doi.org/10.1016/j.jneumeth.2019.06.001>`_
  **A parameterized digital 3D model of the Rhesus macaque face for investigating the visual processing of social cues**. :link-badge:`https://doi.org/10.1016/j.jneumeth.2019.06.001,"J.Neurosci.Methods",cls=badge-primary text-white`

  +++++
  .. image:: _images/Logos/OpenAccess.png
    :height: 30
    :target: https://publicaccess.nih.gov/
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/PDF_button.png
    :height: 30
    :target: _static/PDFs/MF3D_Papers/MurphyLeopold_2019-MacaqueAvatar.pdf
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/PubMed_button.png
    :height: 30
    :target: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7446874/
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/GoogleScholar.png
    :height: 30
    :target: https://scholar.google.com/scholar?cites=9006831545148241977&as_sdt=5,47&sciodt=0,47&hl=en
  .. image:: _images/spacer.png
    :width: 5
  .. image:: _images/Logos/ResearchGate.png
    :height: 30
    :target: https://www.researchgate.net/publication/333700889_A_parameterized_digital_3D_model_of_the_Rhesus_macaque_face_for_investigating_the_visual_processing_of_social_cues


:fa:`pencil` Pre-prints / in prep.
===================================


.. panels::
  :container: container-lg pb-3
  :column: col-lg-12 p-2
  
  ---
  .. image:: _images/Figures/Murphy2022_Fig1.png
    :width: 200
    :align: right

  .. _Murphy2023:

  Murphy AP, Esch EM, Khandhadia AP, Koyano KW, Leopold DA (in prep).
  **Natural stereoscopic depth amplifies face cell responses in macaque.**

  +++++
  .. dropdown:: Abstract

    This study used stereoscopic 3D presentations of the macaque avatar faces to generate realistic depth percepts. Chronic exctracellular neural recordings from three of the face-selective regions of inferotemporal (IT) cortex revealed that many face selective neurons were tuned to faces with natural stereoscopic depth profiles, as opposed to 2D or inverted depth faces. This finding was robust across variations of the stimulus position-in-depth, suggesting that face cells are tuned to 3D shape rather than to specific binocular disparities.
  

  ---
  .. image:: _images/Figures/Murphy2022_Fig1.png
    :width: 200
    :align: right

  .. _Khandhadia2023:

  Khandhadia AP, Murphy AP, Romanksi LM, Bizley JK, Leopold DA (in prep).
  **Audiovisual Integration of Social Information Across Space.**

  +++++
  .. dropdown:: Abstract

    In the macaque, the superior temporal sulcus (STS) is a site of convergence of many different streams of information including auditory, visual, spatial, and social information. In the visual and social domain, the STS contains several face patches, regions which respond more to faces than to non-face objects. However, neurons in anterior fundus (AF) face patch also show modulation by the addition of auditory stimuli to visual stimuli but the precise acoustic information encoded by this modulation remains unknown. Here, we investigated whether spatial factors such as sound direction, gaze direction, or their interaction had an impact on neural responses in this region.

    In this experiment, we recorded from the AF face patch in two macaque monkeys during presentation of audiovisual movies of macaque vocalizations within a virtual reality dome which allowed auditory and visual components to be spatially separated. The subject had to fixate on one of three visual locations. An auditory only, visual only, or audiovisual movie of a vocalizing monkey was then presented. The visual element always arose from the fixation location while the acoustic element, which was always temporally coherent with the movie, played either directly from the location of fixation, or at the same elevation, but shifted 30o to the right or left in azimuth, or at the same azimuth, but 45o above or below the position of fixation. 
  



:fa:`camera` Cameo Appearances
==================================

The macaque avatar appears in figures for illustration purposes (or was used as an experimental stimulus without citation) in the following articles and commentaries:

* **Azadi R, Bohn S, et al. (2023)**. `Image-dependence of the detectability of optogenetic stimulation in macaque inferotemporal cortex <https://doi.org/10.1016/j.cub.2022.12.021>`_. *Curr.Bio.*

* **Fan S, Dal Monte O, Chang SWC (2021)**. `Levels of naturalism in social neuroscience research <https://doi.org/10.1016/j.isci.2021.102702>`_. *iScience*

* **Beauchamp MS (2021)**. `Face and Voice Perception: Monkey see, monkey hear <https://doi.org/10.1016/j.cub.2021.02.060>`_. *Curr.Bio.*

* **Koyano KW, Jones AP, McMahon DBT, Waidmann EN, Russ BE, Leopold DA (2021)**. `Dynamic Suppression of Average Facial Structure Shapes Neural Tuning in Three Macaque Face Patches <https://doi.org/10.1016/j.cub.2020.09.070>`_. *Curr.Bio.*

* **Taubert J & Japee S (2021)**. `Using FACS to trace the neural specializations underlying the recognition of facial expressions: A commentary on Waller et al. (2020) <https://doi.org/10.1016/j.neubiorev.2020.10.016>`_. *Neu.Bio.Rev.*

* **Taubert J, Wardle SG, Ungerleider LG (2020)**. `What does a “face cell” want? <https://doi.org/10.1016/j.pneurobio.2020.101880>`_. *P.Neuro.Bio.*

* **Leopold DA & Krauzlis RJ (2020)**. `How the brain pays attention to others’ attention <https://www.pnas.org/content/117/8/3901>`_. *Curr.Bio.*


:fa:`thumbs-up` Acknowledgements
=========================================

This work was funded by the `National Institute of Mental Health (NIMH) <https://www.nimh.nih.gov/index.shtml>`_ intramural program and utilized the `Neurophysiology Imaging Facility (NIF) <https://www.nimh.nih.gov/research/research-conducted-at-nimh/research-areas/research-support-services/nif/index.shtml>`_ and NIH's `HPC Biowulf cluster <https://hpc.nih.gov/>`_ resources. Stimuli are hosted on `Figshare <https://figshare.com/projects/MF3D_Release_1_A_visual_stimulus_set_of_parametrically_controlled_CGI_macaque_faces_for_research/64544>`_ under the `Creative Commons CC-BY-NC 4.0 <https://creativecommons.org/licenses/by-nc/4.0/>`_ license, while software tools are hosted on `GitHub <https://github.com/MonkeyGone2Heaven/MF3D-Tools>`_ under the `GNU General Public License GNU GPLv3 <https://choosealicense.com/licenses/gpl-3.0/#>`_. All visual stimulus renders were generated using the open-source software `Blender <www.blender.org>`_.



:fa:`handshake` Collaborations
==========================================

Since the initial launch of MF3D, many researchers have contacted us with inquiries regarding adaptation or development of the model's features to address specific scientific questions. At present, our approach is to assess the feasibility of each feature request, and if we determine the required development of the model to be within our capabilities then we will offer to collaborate. This has the advantage for the requester that they don’t have to invest time and effort to learn the technical aspects of 3D animation and rendering in order to get their stimuli, while allowing us to avoid conflicts that could arise from multiple research groups working on the same experimental question simultaneously.
